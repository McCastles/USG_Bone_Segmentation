{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook contains the main Processor pipeline: normalization of the image, filtering and binarization. It is meant to be imported and used in other notebooks."
      ],
      "metadata": {
        "id": "VpUgvL4wseaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Technical Stuff"
      ],
      "metadata": {
        "id": "F-nismvOsoQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Packages Imports"
      ],
      "metadata": {
        "id": "rkmHPE8F-hd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import itertools\n",
        "import random\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "from math import log10, sqrt\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import skimage.morphology as morph\n",
        "import skimage.filters as filters\n",
        "import skimage.feature as feature\n",
        "import skimage.restoration as restoration\n",
        "import skimage.exposure as exposure\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.wiener.html#id1\n",
        "from scipy.signal import wiener\n",
        "# import scipy\n",
        "# scipy.special.seterr(all='ignore')\n",
        "# wiener = scipy.signal.wiener"
      ],
      "metadata": {
        "id": "FI3mudy1XQv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Preprocessor Pipeline"
      ],
      "metadata": {
        "id": "v4U6M3nTYXsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PSNR"
      ],
      "metadata": {
        "id": "c_0IRfkfkP6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Calculate Peak Signal-to-Noise Ratio. \"\"\"\n",
        "def PSNR(original, compressed, LH=True):\n",
        "    if LH:\n",
        "        lower_half = lambda img: img[img.shape[0]//2-50:, :]\n",
        "        mse = np.mean((lower_half(original) - lower_half(compressed)) ** 2)\n",
        "    else:\n",
        "        mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):\n",
        "        return 100\n",
        "    max_pixel = 1.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    return round(psnr, 2)"
      ],
      "metadata": {
        "id": "J6TiAoDVkQMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Existing Ensembles"
      ],
      "metadata": {
        "id": "uz8fUcrvalMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_ensemble( paramset ):\n",
        "\n",
        "    ei = paramset['ENSEMBLE_ID']\n",
        "\n",
        "    if ei == 0:\n",
        "        return {\n",
        "            f'Wiener Filter': lambda img: wiener(img, (2*paramset['WIENER_SIZE'], paramset['WIENER_SIZE'])),\n",
        "            f'TV Chambolle Filter': lambda img: restoration.denoise_tv_chambolle(img, weight=paramset['TV_WEIGHT']), }\n",
        "    \n",
        "    elif ei == 1:\n",
        "        return {\n",
        "            f'Wiener Filter': lambda img: wiener(img, (2*paramset['WIENER_SIZE'], paramset['WIENER_SIZE'])),\n",
        "            f'Median Filter, disk = {paramset[\"MEDIAN_DISK_SIZE\"]}': lambda i: filters.median(i, morph.disk(paramset[\"MEDIAN_DISK_SIZE\"])), }\n",
        "\n",
        "    elif ei == 2:\n",
        "        return {\n",
        "            f'Wavelet Filter': lambda img: restoration.denoise_wavelet( img, wavelet=paramset['WAVELET_TYPE'], rescale_sigma=True ),\n",
        "            f'TV Chambolle Filter': lambda img: restoration.denoise_tv_chambolle(img, weight=paramset['TV_WEIGHT'] ), }\n",
        "\n",
        "    elif ei == 3:\n",
        "        return {\n",
        "            f'Wavelet Filter': lambda img: restoration.denoise_wavelet( img, wavelet=paramset['WAVELET_TYPE'], rescale_sigma=True ),\n",
        "            f'Median Filter, disk = {paramset[\"MEDIAN_DISK_SIZE\"]}': lambda i: filters.median(i, morph.disk(paramset[\"MEDIAN_DISK_SIZE\"])), }\n"
      ],
      "metadata": {
        "id": "i8Szlns6YX35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalization Stage"
      ],
      "metadata": {
        "id": "vSUuCJ9uaTQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Remove small artifacts on the bottom. \"\"\"\n",
        "def cut_artifacts( img ):\n",
        "\n",
        "    i = img.shape[0] - 1\n",
        "    row = img[i, :]\n",
        "    th = row.max()//2\n",
        "    img[i, row > th] = row.min()\n",
        "\n",
        "    for _ in range(10):\n",
        "        i -= 1\n",
        "        row = img[i, :]\n",
        "        img[i, row > th] = row.min()\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "W4q76Cq1Z8ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Tilts the image so that the bottom half is brighter,\n",
        "and the top one is darker. \"\"\"\n",
        "def tilt_image( img, amp=1.0, bottom='brighter' ):\n",
        "\n",
        "    if amp==0:\n",
        "        return img\n",
        "\n",
        "    # Flip if needed\n",
        "    if bottom == 'darker':\n",
        "        img = np.flip(img)\n",
        "\n",
        "    # Skew coefficients\n",
        "    coeffs = np.linspace( -amp, amp, img.shape[0] )\n",
        "\n",
        "    # Application\n",
        "    skew = lambda pv, n: pv + n*(1-pv)*pv\n",
        "    columns = [skew( pv=img[:,col], n=coeffs ) for col in range(img.shape[1])]\n",
        "    app = np.stack( columns ).T\n",
        "\n",
        "    # Normalization\n",
        "    app = (app - app.min()) / (app.max() - app.min())\n",
        "\n",
        "    # Flip back if needed\n",
        "    if bottom == 'darker':\n",
        "        app = np.flip(app)\n",
        "\n",
        "    return app"
      ],
      "metadata": {
        "id": "rmgGdRABZ-GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binarization Stage"
      ],
      "metadata": {
        "id": "-EzplP2raXcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Remove all pixels from the upper half of the image. \"\"\"\n",
        "def remove_upper_half(img, offset=40):\n",
        "    img[:img.shape[0]//2-offset, :] = 0.0\n",
        "    return img"
      ],
      "metadata": {
        "id": "08KYBL6DaFq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Turn grayscale image into a binary one. \"\"\"\n",
        "def binarization( img, method='otsu' ):\n",
        "    methods = {\n",
        "        'otsu': lambda img: filters.threshold_otsu( img ),\n",
        "        'yen': lambda img: filters.threshold_yen( img ),\n",
        "        'adaptive': lambda img: filters.threshold_local(img, block_size=15) }\n",
        "    th = methods[method]( img )\n",
        "    res = img.copy()\n",
        "    res[img > th] = 1.0\n",
        "    res[img <= th] = 0.0\n",
        "    return res"
      ],
      "metadata": {
        "id": "37YiSLcUaGse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Actual Filtering"
      ],
      "metadata": {
        "id": "RBaK1PGIatal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Filters the image and turns it into Binary one. \"\"\"\n",
        "def filter_and_binarize( img, paramset, calculate_psnr=False ):\n",
        "\n",
        "    app = img.copy()\n",
        "\n",
        "    # Normalization Stage\n",
        "    app = cut_artifacts(app)\n",
        "    app = tilt_image(app, amp=paramset['TILT_AMP'], bottom=paramset['TILT_BOTTOM'])\n",
        "    if calculate_psnr:\n",
        "        prefilter = app.copy()\n",
        "\n",
        "    # Filtering Stage\n",
        "    for filter_name, filter_function in choose_ensemble(paramset).items():\n",
        "        app = filter_function(app)\n",
        "\n",
        "    if calculate_psnr:\n",
        "        psnr = PSNR( prefilter, app )\n",
        "\n",
        "    # Binarization Stage\n",
        "    app = binarization(app, method='otsu')\n",
        "    app = remove_upper_half(app)\n",
        "\n",
        "    if calculate_psnr:\n",
        "        return app, psnr\n",
        "    else:\n",
        "        return app\n"
      ],
      "metadata": {
        "id": "6B2ySFk0ZNVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters Estimation"
      ],
      "metadata": {
        "id": "VV4y-HpEbj2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_filter_parameters = [ 'TILT_AMP', 'TILT_BOTTOM', 'WIENER_SIZE', 'MEDIAN_DISK_SIZE', 'WAVELET_TYPE', 'TV_WEIGHT', 'ENSEMBLE_ID' ]\n",
        "columns_image_characteristics = [ 'LH_MEDIAN', 'LH_SUM', 'LH_STD' ]"
      ],
      "metadata": {
        "id": "faouSMVNbk3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_space( df, gt_lenth, radius=0.5 ):\n",
        "\n",
        "    with plt.style.context('dark_background'):\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(6, 6), dpi=90)\n",
        "\n",
        "        colors = {1.0:'red', 2.0:'green', 3.0:'blue', 0.0:'yellow'}\n",
        "\n",
        "        f1 = 'LH_SUM'\n",
        "        f2 = 'LH_MEDIAN'\n",
        "        ax.scatter(df[:gt_lenth][f1], df[:gt_lenth][f2], c=df[:gt_lenth]['LABEL'].map(colors))\n",
        "        \n",
        "        for new_row in df.iloc[gt_lenth:].iterrows():\n",
        "            ax.scatter(new_row[1][f1], new_row[1][f2], color='white')\n",
        "            circle = plt.Circle((new_row[1][f1], new_row[1][f2]), radius, color='white', fill=False)\n",
        "            ax.add_patch(circle)\n",
        "\n",
        "\n",
        "        ax.set_title( f'{f1} vs. {f2}' )\n",
        "        ax.set_xlabel( f1 )\n",
        "        ax.set_ylabel( f2 )"
      ],
      "metadata": {
        "id": "CSzPPNZ5b2CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_KNN( df, radius=0.5, K=3, display=False ):\n",
        "    \n",
        "    for col in columns_image_characteristics:\n",
        "        vec = df[col]\n",
        "        df[col] = (vec - vec.min()) / (vec.max() - vec.min())\n",
        "\n",
        "    X = df.iloc[0:-1]\n",
        "    x = list(df.iloc[-1])\n",
        "\n",
        "    neigh = NearestNeighbors(n_neighbors=K, radius=radius)\n",
        "    neigh.fit(X[columns_image_characteristics])\n",
        "\n",
        "    feat_len = len(columns_image_characteristics)\n",
        "    distances, result = neigh.kneighbors([x[1:feat_len+1]], 3, return_distance=True)\n",
        "    result = result[0]\n",
        "    distances = distances[0]\n",
        "\n",
        "    neigh_ids = []\n",
        "    for i, d in enumerate(distances):\n",
        "        if d <= radius:\n",
        "            neigh_ids.append( result[i] )\n",
        "\n",
        "    if display:\n",
        "        plot_feature_space( df, X.shape[0], radius )\n",
        "\n",
        "    X['WIENER_SIZE'] = X['WIENER_SIZE'].astype('int')\n",
        "    \n",
        "    return list(X.iloc[neigh_ids][['FRAME_NUMBER']+columns_filter_parameters].to_dict('index').values())"
      ],
      "metadata": {
        "id": "HdMJODVEbrwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Original Image + KNN -> Paramset. \"\"\"\n",
        "lower_half = lambda img: img[img.shape[0]//2-50:, :]\n",
        "def estimate_filter_parameters( img, df, patient_id, frame_id ):\n",
        "\n",
        "    \"\"\" Add the new datapoint on the feature space. \"\"\"\n",
        "    img = cv2.resize(img, (0, 0), fx=480/img.shape[1], fy=1)\n",
        "    half = lower_half( img )\n",
        "    row = [None for _ in range(12)]\n",
        "    row[0] = frame_id\n",
        "    row[1] = np.median(half)\n",
        "    row[2] = int(half.sum())\n",
        "    row[3] = np.std(half)\n",
        "    row[-1] = patient_id\n",
        "    dfnorm = df.copy()\n",
        "    dfnorm.loc[len(dfnorm.index)] = row\n",
        "\n",
        "    \"\"\" Normalize and find KNN. \"\"\"\n",
        "    paramsets = find_KNN(dfnorm)\n",
        "    return paramsets\n",
        "    "
      ],
      "metadata": {
        "id": "pZ_q--2QbuML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Preprocessor Function"
      ],
      "metadata": {
        "id": "B_PNfAQbixYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Original Image -> Binarization OR None. \"\"\"\n",
        "def preprocessor(\n",
        "        img,         # Original Frame\n",
        "        df,          # The Reference Table\n",
        "        frame_id,    # Frame Number\n",
        "        patient_id,  # Patient Number\n",
        "        display=True ):\n",
        "    \n",
        "    paramsets = estimate_filter_parameters( img, df, patient_id, frame_id )\n",
        "    N = len(paramsets)\n",
        "    if display:\n",
        "        print(f'Paramsets found: {N}')\n",
        "    if N == 0:\n",
        "        if display:\n",
        "            print(f'Frame #{frame_id} is too noisy, no structure recognized.')\n",
        "        return None\n",
        "    \n",
        "    best = {'psnr': 0, 'binimg': None, 'paramset': None}\n",
        "    for paramset in paramsets:\n",
        "        binimg, psnr = filter_and_binarize( img, paramset, calculate_psnr=True )\n",
        "        if psnr > best['psnr']:\n",
        "            best['psnr'] = psnr\n",
        "            best['binimg'] = binimg\n",
        "            best['paramset'] = paramset\n",
        "    if display:\n",
        "        shows(imgs=[img, best['binimg']], titles=[f'Frame #{frame_id}', f'After Preprocessing, PSNR={best[\"psnr\"]}'], dpi=120)\n",
        "    return best['binimg']"
      ],
      "metadata": {
        "id": "zKwMdhLAcJXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Usage. \"\"\"\n",
        "# binimg = preprocessor( img, df, FRAME_ID, PATIENT_ID, display=False )"
      ],
      "metadata": {
        "id": "r5G7kAgHcAe-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}